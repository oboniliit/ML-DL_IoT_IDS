{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "BLSTM_NSL_KDD.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WRBWrw8eR9J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25116928-5468-4404-f7c7-f8807123a36d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWUjtt6KHH0T",
        "outputId": "cabdf1d6-d1a8-4566-c4ca-4bc229960ad0"
      },
      "source": [
        "!pip install scikit-plot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-plot\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/47/32520e259340c140a4ad27c1b97050dd3254fdc517b1d59974d47037510e/scikit_plot-0.3.7-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (3.2.2)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.17.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (1.4.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUNXp18BZaFk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "2ca85c47-524a-4c2c-d801-9804a462f288"
      },
      "source": [
        "from plotly.offline import init_notebook_mode, iplot, plot\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import re\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from scipy.io import arff\n",
        "init_notebook_mode(connected=True)\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Bidirectional\n",
        "from keras.models import Sequential\n",
        "import scikitplot as skplt\n",
        "import h5py\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error,roc_auc_score,cohen_kappa_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkFqyfp9ZaFq"
      },
      "source": [
        " #load training dataset\n",
        "dataTrain = arff.loadarff('/content/drive/MyDrive/KDDTrain20MultiClass.arff')\n",
        "dataset_train = pd.DataFrame(dataTrain[0])\n",
        "dataTest = arff.loadarff('/content/drive/My Drive/KDDTest21MultiClass.arff')\n",
        "dataset_test= pd.DataFrame(dataTrain[0])\n",
        "\n",
        "X_train = dataset_train.iloc[:, :-2].values\n",
        "Y_train = dataset_train.iloc[:, 41].values\n",
        "\n",
        "X_test = dataset_test.iloc[:, :-2].values\n",
        "Y_test = dataset_test.iloc[:, 41].values "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WWxx9TE9hjw"
      },
      "source": [
        "classes=[0,1,2,3,4,5]\r\n",
        "n_classes = 6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlghbNSJfSxp"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "X_train.shape\n",
        "\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "x_train = np.array(X_train)\n",
        "x_test = np.array(X_test)\n",
        "y_train1 = np.array(Y_train)\n",
        "y_test1 = np.array(Y_test)\n",
        "\n",
        "y_train= to_categorical(y_train1)\n",
        "y_test= to_categorical(y_test1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVMrAc_bEC9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca1d1f45-ebf9-4ac7-cb57-ee5a987ac159"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(80, input_dim=40, return_sequences=True)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Bidirectional(LSTM(40)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(6, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "#model.summary()\n",
        "\n",
        "model.fit(X_train, y_train, epochs=15, batch_size=64, verbose=1)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "# save model and architecture to single file\n",
        "model.save(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "394/394 [==============================] - 3s 7ms/step - loss: 0.2323 - accuracy: 0.9495\n",
            "Epoch 2/15\n",
            "394/394 [==============================] - 2s 6ms/step - loss: 0.0512 - accuracy: 0.9824\n",
            "Epoch 3/15\n",
            "394/394 [==============================] - 3s 6ms/step - loss: 0.0403 - accuracy: 0.9862\n",
            "Epoch 4/15\n",
            "394/394 [==============================] - 2s 6ms/step - loss: 0.0336 - accuracy: 0.9886\n",
            "Epoch 5/15\n",
            "394/394 [==============================] - 3s 6ms/step - loss: 0.0318 - accuracy: 0.9889\n",
            "Epoch 6/15\n",
            "394/394 [==============================] - 2s 6ms/step - loss: 0.0293 - accuracy: 0.9896\n",
            "Epoch 7/15\n",
            "394/394 [==============================] - 3s 7ms/step - loss: 0.0276 - accuracy: 0.9903\n",
            "Epoch 8/15\n",
            "394/394 [==============================] - 2s 6ms/step - loss: 0.0258 - accuracy: 0.9909\n",
            "Epoch 9/15\n",
            "394/394 [==============================] - 2s 6ms/step - loss: 0.0252 - accuracy: 0.9914\n",
            "Epoch 10/15\n",
            "394/394 [==============================] - 3s 6ms/step - loss: 0.0236 - accuracy: 0.9923\n",
            "Epoch 11/15\n",
            "394/394 [==============================] - 3s 7ms/step - loss: 0.0228 - accuracy: 0.9926\n",
            "Epoch 12/15\n",
            "394/394 [==============================] - 2s 6ms/step - loss: 0.0223 - accuracy: 0.9924\n",
            "Epoch 13/15\n",
            "394/394 [==============================] - 3s 7ms/step - loss: 0.0209 - accuracy: 0.9929\n",
            "Epoch 14/15\n",
            "394/394 [==============================] - 3s 6ms/step - loss: 0.0194 - accuracy: 0.9929\n",
            "Epoch 15/15\n",
            "394/394 [==============================] - 2s 6ms/step - loss: 0.0191 - accuracy: 0.9934\n",
            "accuracy: 99.28%\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_kUy7bm90X3"
      },
      "source": [
        "target_names = ['DoS', 'U2R', 'R2L', 'Probe','Normal','Unknown']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZmi69ou8tOG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de228406-39c9-4928-bb8d-39fcfeb02cc3"
      },
      "source": [
        "### train_accuracy\r\n",
        "import sklearn.metrics as metrics\r\n",
        "expected = y_train\r\n",
        "predicted = model.predict(X_train)\r\n",
        "data = classification_report(expected,np.round(predicted), target_names=target_names)\r\n",
        "print(data)\r\n",
        "\r\n",
        "print(\"Accuracy_Train:\",metrics.accuracy_score(expected, np.round(predicted)))\r\n",
        "print(\"Precision_Train:\",metrics.precision_score(expected, np.round(predicted), average='weighted'))\r\n",
        "print(\"Recall_Train:\",metrics.recall_score(expected, np.round(predicted), average='weighted'))\r\n",
        "print(\"f1-score_Train:\",metrics.f1_score(expected, np.round(predicted), average='weighted'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         DoS       0.00      0.00      0.00         0\n",
            "         U2R       1.00      1.00      1.00      9234\n",
            "         R2L       1.00      0.55      0.71        11\n",
            "       Probe       0.82      0.84      0.83       209\n",
            "      Normal       0.98      0.98      0.98      2289\n",
            "     Unknown       0.99      0.99      0.99     13449\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     25192\n",
            "   macro avg       0.80      0.73      0.75     25192\n",
            "weighted avg       0.99      0.99      0.99     25192\n",
            " samples avg       0.99      0.99      0.99     25192\n",
            "\n",
            "Accuracy_Train: 0.9927357891394093\n",
            "Precision_Train: 0.9928965462384829\n",
            "Recall_Train: 0.9927357891394093\n",
            "f1-score_Train: 0.9927852714648865\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning:\n",
            "\n",
            "F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ4XTtdfZaF5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ed65ce4-0348-41a8-8afa-2b690e3e3f7a"
      },
      "source": [
        "### test_accuracy\n",
        "import sklearn.metrics as metrics\n",
        "target_names = ['DoS', 'U2R', 'R2L', 'Probe', 'Normal', 'Unknown']\n",
        "expected = y_test\n",
        "predicted = model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\",metrics.accuracy_score(expected, np.round(predicted)))\n",
        "print(\"Precision:\",metrics.precision_score(expected, np.round(predicted), average='weighted'))\n",
        "print(\"Recall:\",metrics.recall_score(expected, np.round(predicted), average='weighted'))\n",
        "print(\"f1-score:\",metrics.f1_score(expected, np.round(predicted), average='weighted'))\n",
        "expected_test = np.array([0, 1, 0, 0])\n",
        "predicted_test = np.array([1, 0, 0, 0])\n",
        "auc = roc_auc_score(expected_test, predicted_test, average='weighted', multi_class=\"ovr\")\n",
        "print('ROC AUC: %f' % auc)\n",
        "print(classification_report(expected, np.round(predicted), target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9927357891394093\n",
            "Precision: 0.9928965462384829\n",
            "Recall: 0.9927357891394093\n",
            "f1-score: 0.9927852714648865\n",
            "ROC AUC: 0.333333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         DoS       0.00      0.00      0.00         0\n",
            "         U2R       1.00      1.00      1.00      9234\n",
            "         R2L       1.00      0.55      0.71        11\n",
            "       Probe       0.82      0.84      0.83       209\n",
            "      Normal       0.98      0.98      0.98      2289\n",
            "     Unknown       0.99      0.99      0.99     13449\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     25192\n",
            "   macro avg       0.80      0.73      0.75     25192\n",
            "weighted avg       0.99      0.99      0.99     25192\n",
            " samples avg       0.99      0.99      0.99     25192\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning:\n",
            "\n",
            "F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}