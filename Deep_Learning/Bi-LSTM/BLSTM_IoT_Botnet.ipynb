{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "BLSTM_IoT_Botnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FDjw6UZK40D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96f41a5e-a8e4-4361-98ff-b6c33f3cea10"
      },
      "source": [
        "!pip install scikit-plot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-plot\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/47/32520e259340c140a4ad27c1b97050dd3254fdc517b1d59974d47037510e/scikit_plot-0.3.7-py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.17.0)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->scikit-plot) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIrd8fe_iX0K"
      },
      "source": [
        "# Load libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, auc\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding, Flatten, LSTM\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import learning_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import scikitplot as skplt\n",
        "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from scipy import interp\n",
        "from itertools import cycle\n",
        "from sklearn.model_selection import KFold,cross_val_score\n",
        "kfold=KFold(5,True,3)\n",
        "cvscores = []\n",
        "import h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZiyemdtLsxe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a705e01-de76-4d5f-8b0c-30217f434e8a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XveDLziHK40S"
      },
      "source": [
        " # data is being refined, Here we fist get our data to be converted into pandas dataframae\n",
        "# then we drop empty spaces and eradicate useless indices and getting data in float type\n",
        "def cleaningdata(df):\n",
        "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
        "    df.dropna(inplace=True)\n",
        "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
        "    return df[indices_to_keep].astype(np.float64)\n",
        "# fetching dataset from path\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/Code/dataset/IoT-BoT.csv', encoding='utf-8')\n",
        "# for object type data we will label it and transform into apporopriate type fo data after using fit_transform on that colomn to avoid errors\n",
        "for column in dataset.columns:\n",
        "    if dataset[column].dtype == type(object):\n",
        "        le = LabelEncoder()\n",
        "        dataset[column] = le.fit_transform(dataset[column])\n",
        "ds = cleaningdata(dataset)\n",
        "X = ds.iloc[:, 0:85].values\n",
        "# collecting our LABEL colomn in y\n",
        "y = ds.iloc[:, -2].values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgiiAioi_4_M"
      },
      "source": [
        "#### BLSTM #######\r\n",
        "def cleaningdata(df):\r\n",
        "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\r\n",
        "    df.dropna(inplace=True)\r\n",
        "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\r\n",
        "    return df[indices_to_keep].astype(np.float64)\r\n",
        "# fetching dataset from path\r\n",
        "dataset = pd.read_csv('/content/drive/My Drive/Code/dataset/IoT Intrusion Dataset 2020.csv', encoding='utf-8')\r\n",
        "# for object type data we will label it and transform into apporopriate type fo data after using fit_transform on that colomn to avoid errors\r\n",
        "for column in dataset.columns:\r\n",
        "    if dataset[column].dtype == type(object):\r\n",
        "        le = LabelEncoder()\r\n",
        "        dataset[column] = le.fit_transform(dataset[column])\r\n",
        "data = cleaningdata(dataset)\r\n",
        "\r\n",
        "# collecting all required colomns in data to X\r\n",
        "X = data.iloc[:, 0:85].values\r\n",
        "\r\n",
        "# collecting our LABEL colomn in y\r\n",
        "y = data.iloc[:, -2].values\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxIWKm2gtZ3A",
        "outputId": "91219f74-a5f8-4670-80ef-df11bdea1fb6"
      },
      "source": [
        "for train, test in kfold.split(X,y):\r\n",
        "   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=52)\r\n",
        "   from keras.utils.np_utils import to_categorical\r\n",
        "   sc = StandardScaler()\r\n",
        "   X_train = sc.fit_transform(X_train)\r\n",
        "   X_test = sc.transform(X_test)\r\n",
        "\r\n",
        "   X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\r\n",
        "   X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\r\n",
        "\r\n",
        "   x_train = np.array(X_train)\r\n",
        "   x_test = np.array(X_test)\r\n",
        "   y_train1 = np.array(y_train)\r\n",
        "   y_test1 = np.array(y_test)\r\n",
        "\r\n",
        "   y_train= to_categorical(y_train1)\r\n",
        "   y_test= to_categorical(y_test1)\r\n",
        "# 1. define the network\r\n",
        "   from keras.layers import Bidirectional\r\n",
        "   model = Sequential()\r\n",
        "   model.add(Bidirectional(LSTM(80, input_dim=85, return_sequences=True)))\r\n",
        "   model.add(Dropout(0.1))\r\n",
        "   model.add(Bidirectional(LSTM(40)))\r\n",
        "   model.add(Dropout(0.1))\r\n",
        "   model.add(Dense(128, activation='relu'))\r\n",
        "   model.add(Dropout(0.1))\r\n",
        "   model.add(Dense(5, activation='softmax'))\r\n",
        "   model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy','mae'])\r\n",
        "   history = model.fit(X_train, y_train, epochs = 15, batch_size=64, verbose=1,shuffle=False)\r\n",
        "   scores = model.evaluate(X_test, y_test, verbose=1)\r\n",
        "   print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\r\n",
        "   cvscores.append(scores[1] * 100)\r\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "7818/7818 [==============================] - 54s 7ms/step - loss: 0.0114 - accuracy: 0.9969 - mae: 0.0025\n",
            "Epoch 2/15\n",
            "7818/7818 [==============================] - 56s 7ms/step - loss: 8.4819e-04 - accuracy: 0.9998 - mae: 1.2615e-04\n",
            "Epoch 3/15\n",
            "7818/7818 [==============================] - 56s 7ms/step - loss: 5.6785e-04 - accuracy: 0.9998 - mae: 8.3241e-05\n",
            "Epoch 4/15\n",
            "7818/7818 [==============================] - 57s 7ms/step - loss: 5.1402e-04 - accuracy: 0.9999 - mae: 7.4885e-05\n",
            "Epoch 5/15\n",
            "7818/7818 [==============================] - 56s 7ms/step - loss: 4.0382e-04 - accuracy: 0.9999 - mae: 5.7162e-05\n",
            "Epoch 6/15\n",
            "7818/7818 [==============================] - 56s 7ms/step - loss: 3.7946e-04 - accuracy: 0.9999 - mae: 5.0787e-05\n",
            "Epoch 7/15\n",
            "7818/7818 [==============================] - 56s 7ms/step - loss: 3.0643e-04 - accuracy: 0.9999 - mae: 4.4155e-05\n",
            "Epoch 8/15\n",
            "7818/7818 [==============================] - 58s 7ms/step - loss: 2.5443e-04 - accuracy: 0.9999 - mae: 3.5023e-05\n",
            "Epoch 9/15\n",
            "7818/7818 [==============================] - 59s 8ms/step - loss: 3.4294e-04 - accuracy: 0.9999 - mae: 3.9575e-05\n",
            "Epoch 10/15\n",
            "7818/7818 [==============================] - 59s 8ms/step - loss: 1.5155e-04 - accuracy: 1.0000 - mae: 2.1703e-05\n",
            "Epoch 11/15\n",
            "7818/7818 [==============================] - 57s 7ms/step - loss: 2.8474e-04 - accuracy: 0.9999 - mae: 2.7271e-05\n",
            "Epoch 12/15\n",
            "7818/7818 [==============================] - 59s 7ms/step - loss: 2.6220e-04 - accuracy: 0.9999 - mae: 2.9344e-05\n",
            "Epoch 13/15\n",
            "7818/7818 [==============================] - 60s 8ms/step - loss: 2.1833e-04 - accuracy: 1.0000 - mae: 2.3572e-05\n",
            "Epoch 14/15\n",
            "7818/7818 [==============================] - 59s 8ms/step - loss: 2.2384e-04 - accuracy: 1.0000 - mae: 1.9976e-05\n",
            "Epoch 15/15\n",
            "7818/7818 [==============================] - 58s 7ms/step - loss: 1.0156e-04 - accuracy: 1.0000 - mae: 1.5549e-05\n",
            "3909/3909 [==============================] - 7s 2ms/step - loss: 4.0784e-04 - accuracy: 0.9999 - mae: 2.6277e-05\n",
            "accuracy: 99.99%\n",
            "Epoch 1/15\n",
            "7818/7818 [==============================] - 56s 7ms/step - loss: 0.0117 - accuracy: 0.9968 - mae: 0.0025\n",
            "Epoch 2/15\n",
            "7818/7818 [==============================] - 59s 8ms/step - loss: 7.5488e-04 - accuracy: 0.9998 - mae: 1.2271e-04\n",
            "Epoch 3/15\n",
            "7818/7818 [==============================] - 59s 8ms/step - loss: 6.6448e-04 - accuracy: 0.9998 - mae: 9.4994e-05\n",
            "Epoch 4/15\n",
            "7818/7818 [==============================] - 60s 8ms/step - loss: 6.0999e-04 - accuracy: 0.9998 - mae: 8.2419e-05\n",
            "Epoch 5/15\n",
            "7818/7818 [==============================] - 61s 8ms/step - loss: 4.3939e-04 - accuracy: 0.9999 - mae: 5.9428e-05\n",
            "Epoch 6/15\n",
            "7818/7818 [==============================] - 62s 8ms/step - loss: 4.8190e-04 - accuracy: 0.9999 - mae: 5.4942e-05\n",
            "Epoch 7/15\n",
            "7818/7818 [==============================] - 58s 7ms/step - loss: 3.4868e-04 - accuracy: 0.9999 - mae: 5.0673e-05\n",
            "Epoch 8/15\n",
            "7818/7818 [==============================] - 59s 8ms/step - loss: 2.7578e-04 - accuracy: 0.9999 - mae: 3.8384e-05\n",
            "Epoch 9/15\n",
            "7818/7818 [==============================] - 60s 8ms/step - loss: 3.3914e-04 - accuracy: 0.9999 - mae: 4.0439e-05\n",
            "Epoch 10/15\n",
            "7818/7818 [==============================] - 60s 8ms/step - loss: 4.0575e-04 - accuracy: 0.9999 - mae: 4.3289e-05\n",
            "Epoch 11/15\n",
            "7818/7818 [==============================] - 59s 8ms/step - loss: 2.8300e-04 - accuracy: 0.9999 - mae: 3.1310e-05\n",
            "Epoch 12/15\n",
            "7818/7818 [==============================] - 57s 7ms/step - loss: 3.3399e-04 - accuracy: 1.0000 - mae: 2.7052e-05\n",
            "Epoch 13/15\n",
            "7818/7818 [==============================] - 58s 7ms/step - loss: 2.6824e-04 - accuracy: 0.9999 - mae: 3.4332e-05\n",
            "Epoch 14/15\n",
            "7818/7818 [==============================] - 56s 7ms/step - loss: 1.0468e-04 - accuracy: 1.0000 - mae: 1.6074e-05\n",
            "Epoch 15/15\n",
            "7818/7818 [==============================] - 57s 7ms/step - loss: 2.1299e-04 - accuracy: 1.0000 - mae: 1.6701e-05\n",
            "3909/3909 [==============================] - 7s 2ms/step - loss: 4.6064e-04 - accuracy: 0.9999 - mae: 3.7288e-05\n",
            "accuracy: 99.99%\n",
            "Epoch 1/15\n",
            "7818/7818 [==============================] - 56s 7ms/step - loss: 0.0116 - accuracy: 0.9969 - mae: 0.0025\n",
            "Epoch 2/15\n",
            "7818/7818 [==============================] - 58s 7ms/step - loss: 7.0796e-04 - accuracy: 0.9998 - mae: 1.1933e-04\n",
            "Epoch 3/15\n",
            "7818/7818 [==============================] - 57s 7ms/step - loss: 5.5948e-04 - accuracy: 0.9999 - mae: 8.0207e-05\n",
            "Epoch 4/15\n",
            "7818/7818 [==============================] - 60s 8ms/step - loss: 4.9072e-04 - accuracy: 0.9999 - mae: 6.7383e-05\n",
            "Epoch 5/15\n",
            "7818/7818 [==============================] - 58s 7ms/step - loss: 6.3647e-04 - accuracy: 0.9999 - mae: 7.6924e-05\n",
            "Epoch 6/15\n",
            "7818/7818 [==============================] - 55s 7ms/step - loss: 3.4593e-04 - accuracy: 0.9999 - mae: 4.9152e-05\n",
            "Epoch 7/15\n",
            "7818/7818 [==============================] - 57s 7ms/step - loss: 3.6810e-04 - accuracy: 0.9999 - mae: 5.1783e-05\n",
            "Epoch 8/15\n",
            "7818/7818 [==============================] - 56s 7ms/step - loss: 3.5633e-04 - accuracy: 0.9999 - mae: 4.3109e-05\n",
            "Epoch 9/15\n",
            "7818/7818 [==============================] - 57s 7ms/step - loss: 1.9509e-04 - accuracy: 0.9999 - mae: 3.0141e-05\n",
            "Epoch 10/15\n",
            "7818/7818 [==============================] - 56s 7ms/step - loss: 3.8050e-04 - accuracy: 0.9999 - mae: 3.2501e-05\n",
            "Epoch 11/15\n",
            "7818/7818 [==============================] - 56s 7ms/step - loss: 2.8020e-04 - accuracy: 0.9999 - mae: 3.5956e-05\n",
            "Epoch 12/15\n",
            "7818/7818 [==============================] - 57s 7ms/step - loss: 2.1612e-04 - accuracy: 0.9999 - mae: 2.8290e-05\n",
            "Epoch 13/15\n",
            "7818/7818 [==============================] - 56s 7ms/step - loss: 2.2652e-04 - accuracy: 1.0000 - mae: 2.4373e-05\n",
            "Epoch 14/15\n",
            "7818/7818 [==============================] - 60s 8ms/step - loss: 2.7245e-04 - accuracy: 0.9999 - mae: 2.6008e-05\n",
            "Epoch 15/15\n",
            "7818/7818 [==============================] - 60s 8ms/step - loss: 1.8442e-04 - accuracy: 1.0000 - mae: 1.9837e-05\n",
            "3909/3909 [==============================] - 7s 2ms/step - loss: 4.3238e-04 - accuracy: 0.9999 - mae: 4.5301e-05\n",
            "accuracy: 99.99%\n",
            "Epoch 1/15\n",
            "7818/7818 [==============================] - 56s 7ms/step - loss: 0.0117 - accuracy: 0.9968 - mae: 0.0025\n",
            "Epoch 2/15\n",
            "7818/7818 [==============================] - 55s 7ms/step - loss: 7.7480e-04 - accuracy: 0.9998 - mae: 1.2562e-04\n",
            "Epoch 3/15\n",
            "7818/7818 [==============================] - 58s 7ms/step - loss: 5.5795e-04 - accuracy: 0.9998 - mae: 8.9680e-05\n",
            "Epoch 4/15\n",
            "7818/7818 [==============================] - 62s 8ms/step - loss: 4.7896e-04 - accuracy: 0.9999 - mae: 7.0913e-05\n",
            "Epoch 5/15\n",
            "7818/7818 [==============================] - 64s 8ms/step - loss: 5.3410e-04 - accuracy: 0.9999 - mae: 6.0079e-05\n",
            "Epoch 6/15\n",
            "7818/7818 [==============================] - 60s 8ms/step - loss: 3.6600e-04 - accuracy: 0.9999 - mae: 4.7629e-05\n",
            "Epoch 7/15\n",
            "7818/7818 [==============================] - 60s 8ms/step - loss: 2.7519e-04 - accuracy: 0.9999 - mae: 3.7003e-05\n",
            "Epoch 8/15\n",
            "7818/7818 [==============================] - 61s 8ms/step - loss: 2.9913e-04 - accuracy: 0.9999 - mae: 3.9467e-05\n",
            "Epoch 9/15\n",
            "7818/7818 [==============================] - 61s 8ms/step - loss: 2.7884e-04 - accuracy: 0.9999 - mae: 3.2154e-05\n",
            "Epoch 10/15\n",
            "7818/7818 [==============================] - 61s 8ms/step - loss: 2.9025e-04 - accuracy: 0.9999 - mae: 3.7174e-05\n",
            "Epoch 11/15\n",
            "7818/7818 [==============================] - 57s 7ms/step - loss: 3.2801e-04 - accuracy: 0.9999 - mae: 3.1910e-05\n",
            "Epoch 12/15\n",
            "7818/7818 [==============================] - 55s 7ms/step - loss: 2.1755e-04 - accuracy: 1.0000 - mae: 2.1417e-05\n",
            "Epoch 13/15\n",
            "7818/7818 [==============================] - 56s 7ms/step - loss: 1.8649e-04 - accuracy: 1.0000 - mae: 1.8583e-05\n",
            "Epoch 14/15\n",
            "7818/7818 [==============================] - 58s 7ms/step - loss: 2.4101e-04 - accuracy: 0.9999 - mae: 2.5412e-05\n",
            "Epoch 15/15\n",
            "7818/7818 [==============================] - 57s 7ms/step - loss: 2.1337e-04 - accuracy: 1.0000 - mae: 1.7883e-05\n",
            "3909/3909 [==============================] - 7s 2ms/step - loss: 3.2722e-04 - accuracy: 0.9999 - mae: 3.9831e-05\n",
            "accuracy: 99.99%\n",
            "Epoch 1/15\n",
            "7818/7818 [==============================] - 57s 7ms/step - loss: 0.0114 - accuracy: 0.9969 - mae: 0.0025\n",
            "Epoch 2/15\n",
            "7818/7818 [==============================] - 57s 7ms/step - loss: 8.3200e-04 - accuracy: 0.9998 - mae: 1.2706e-04\n",
            "Epoch 3/15\n",
            "7818/7818 [==============================] - 54s 7ms/step - loss: 5.7650e-04 - accuracy: 0.9998 - mae: 8.7327e-05\n",
            "Epoch 4/15\n",
            "7818/7818 [==============================] - 54s 7ms/step - loss: 6.6709e-04 - accuracy: 0.9998 - mae: 8.8534e-05\n",
            "Epoch 5/15\n",
            "7818/7818 [==============================] - 55s 7ms/step - loss: 3.7381e-04 - accuracy: 0.9999 - mae: 4.9282e-05\n",
            "Epoch 6/15\n",
            "7818/7818 [==============================] - 57s 7ms/step - loss: 3.8420e-04 - accuracy: 0.9999 - mae: 5.1907e-05\n",
            "Epoch 7/15\n",
            "7818/7818 [==============================] - 53s 7ms/step - loss: 2.8863e-04 - accuracy: 0.9999 - mae: 4.1242e-05\n",
            "Epoch 8/15\n",
            "7818/7818 [==============================] - 54s 7ms/step - loss: 3.2236e-04 - accuracy: 0.9999 - mae: 3.7414e-05\n",
            "Epoch 9/15\n",
            "7818/7818 [==============================] - 57s 7ms/step - loss: 3.2870e-04 - accuracy: 0.9999 - mae: 4.3249e-05\n",
            "Epoch 10/15\n",
            "7818/7818 [==============================] - 53s 7ms/step - loss: 3.1048e-04 - accuracy: 0.9999 - mae: 3.2147e-05\n",
            "Epoch 11/15\n",
            "7818/7818 [==============================] - 54s 7ms/step - loss: 2.3064e-04 - accuracy: 0.9999 - mae: 2.5960e-05\n",
            "Epoch 12/15\n",
            "7818/7818 [==============================] - 53s 7ms/step - loss: 2.0485e-04 - accuracy: 1.0000 - mae: 2.5479e-05\n",
            "Epoch 13/15\n",
            "7818/7818 [==============================] - 52s 7ms/step - loss: 2.7572e-04 - accuracy: 0.9999 - mae: 3.0149e-05\n",
            "Epoch 14/15\n",
            "7818/7818 [==============================] - 55s 7ms/step - loss: 1.6347e-04 - accuracy: 1.0000 - mae: 2.1370e-05\n",
            "Epoch 15/15\n",
            "7818/7818 [==============================] - 54s 7ms/step - loss: 2.6747e-04 - accuracy: 1.0000 - mae: 2.0739e-05\n",
            "3909/3909 [==============================] - 7s 2ms/step - loss: 4.5368e-04 - accuracy: 0.9999 - mae: 3.3304e-05\n",
            "accuracy: 99.99%\n",
            "99.99% (+/- 0.00%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t6ABz5tK40p"
      },
      "source": [
        "target_names = ['DoS', 'DDOS', 'Reconnaissance', 'Normal','Theft']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJNjYaO88Zax",
        "outputId": "4ac708cb-5c9c-4f3a-8fd6-bc101244c6c6"
      },
      "source": [
        "y_pred_test = model.predict(X_test)\r\n",
        "# print test_scores of accuracy,precision,recall,f1-score\r\n",
        "print(\"Test_Accuracy:\",metrics.accuracy_score(y_test, np.round(y_pred_test)))\r\n",
        "print(\"Test_Precision:\",metrics.precision_score(y_test, np.round(y_pred_test), average='weighted'))\r\n",
        "print(\"Test_Recall:\",metrics.recall_score(y_test, np.round(y_pred_test), average='weighted'))\r\n",
        "print(\"Test_f1-score:\",metrics.f1_score(y_test, np.round(y_pred_test), average='weighted'))\r\n",
        "print(classification_report(y_test, np.round(y_pred_test), target_names=target_names))\r\n",
        "\r\n",
        "# print train_scores of accuracy,precision,recall,f1-score\r\n",
        "y_pred_train = model.predict(X_train)\r\n",
        "print(\"Train_Accuracy:\",metrics.accuracy_score(y_train, np.round(y_pred_train)))\r\n",
        "print(\"Train_Precision:\",metrics.precision_score(y_train, np.round(y_pred_train), average='weighted'))\r\n",
        "print(\"Train_Recall:\",metrics.recall_score(y_train, np.round(y_pred_train), average='weighted'))\r\n",
        "print(\"Train_f1-score:\",metrics.f1_score(y_train, np.round(y_pred_train), average='weighted'))\r\n",
        "print(classification_report(y_train, np.round(y_pred_train), target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test_Accuracy: 0.9999120583932269\n",
            "Test_Precision: 0.9999120697742933\n",
            "Test_Recall: 0.9999120583932269\n",
            "Test_f1-score: 0.999912059304131\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "           DoS       1.00      1.00      1.00     11815\n",
            "          DDOS       1.00      1.00      1.00      7109\n",
            "Reconnaissance       1.00      1.00      1.00     83057\n",
            "        Normal       1.00      1.00      1.00      8060\n",
            "         Theft       1.00      1.00      1.00     15042\n",
            "\n",
            "     micro avg       1.00      1.00      1.00    125083\n",
            "     macro avg       1.00      1.00      1.00    125083\n",
            "  weighted avg       1.00      1.00      1.00    125083\n",
            "   samples avg       1.00      1.00      1.00    125083\n",
            "\n",
            "Train_Accuracy: 0.9999760159254255\n",
            "Train_Precision: 0.999976016867048\n",
            "Train_Recall: 0.9999760159254255\n",
            "Train_f1-score: 0.9999760160333039\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "           DoS       1.00      1.00      1.00     47576\n",
            "          DDOS       1.00      1.00      1.00     28268\n",
            "Reconnaissance       1.00      1.00      1.00    332252\n",
            "        Normal       1.00      1.00      1.00     32013\n",
            "         Theft       1.00      1.00      1.00     60223\n",
            "\n",
            "     micro avg       1.00      1.00      1.00    500332\n",
            "     macro avg       1.00      1.00      1.00    500332\n",
            "  weighted avg       1.00      1.00      1.00    500332\n",
            "   samples avg       1.00      1.00      1.00    500332\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}