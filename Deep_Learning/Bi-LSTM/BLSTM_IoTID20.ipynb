{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "BLSTM_IoTID20.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FDjw6UZK40D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d7c24b7-d0ca-462c-a72d-b36b6cd69809"
      },
      "source": [
        "!pip install scikit-plot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-plot\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/47/32520e259340c140a4ad27c1b97050dd3254fdc517b1d59974d47037510e/scikit_plot-0.3.7-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (3.2.2)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.17.0)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.22.2.post1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.18.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIrd8fe_iX0K"
      },
      "source": [
        "# Load libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, auc\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding, Flatten, LSTM\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import learning_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import scikitplot as skplt\n",
        "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from scipy import interp\n",
        "from itertools import cycle\n",
        "from sklearn.model_selection import KFold,cross_val_score\n",
        "kfold=KFold(5,True,3)\n",
        "cvscores = []\n",
        "import h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZiyemdtLsxe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e54b1b8-c886-4603-e10b-dde798a1587e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XveDLziHK40S"
      },
      "source": [
        " # data is being refined, Here we fist get our data to be converted into pandas dataframae\n",
        "# then we drop empty spaces and eradicate useless indices and getting data in float type\n",
        "def cleaningdata(df):\n",
        "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
        "    df.dropna(inplace=True)\n",
        "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
        "    return df[indices_to_keep].astype(np.float64)\n",
        "# fetching dataset from path\n",
        "dataset = pd.read_csv('/content/drive/My Drive/Code/dataset/IoT Intrusion Dataset 2020.csv', encoding='utf-8')\n",
        "# for object type data we will label it and transform into apporopriate type fo data after using fit_transform on that colomn to avoid errors\n",
        "for column in dataset.columns:\n",
        "    if dataset[column].dtype == type(object):\n",
        "        le = LabelEncoder()\n",
        "        dataset[column] = le.fit_transform(dataset[column])\n",
        "ds = cleaningdata(dataset)\n",
        "# collecting all required colomns in data to X\n",
        "X = ds.iloc[:, 0:85].values\n",
        "# collecting our LABEL colomn in y\n",
        "y = ds.iloc[:, -2].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DON6COOUnUTL",
        "outputId": "0e1471fc-25ba-4f23-bb81-4f6c1e652315"
      },
      "source": [
        "for train, test in kfold.split(X,y):\r\n",
        "   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=52)\r\n",
        "   from keras.utils.np_utils import to_categorical\r\n",
        "   sc = StandardScaler()\r\n",
        "   X_train = sc.fit_transform(X_train)\r\n",
        "   X_test = sc.transform(X_test)\r\n",
        "\r\n",
        "   #X_train.shape\r\n",
        "\r\n",
        "   X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\r\n",
        "   X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\r\n",
        "\r\n",
        "   x_train = np.array(X_train)\r\n",
        "   x_test = np.array(X_test)\r\n",
        "   y_train1 = np.array(y_train)\r\n",
        "   y_test1 = np.array(y_test)\r\n",
        "\r\n",
        "   y_train= to_categorical(y_train1)\r\n",
        "   y_test= to_categorical(y_test1)\r\n",
        "\r\n",
        "   # 1. define the network\r\n",
        "   from keras.layers import Bidirectional\r\n",
        "   model = Sequential()\r\n",
        "   model.add(Bidirectional(LSTM(80, input_dim=85, return_sequences=True)))\r\n",
        "   model.add(Dropout(0.1))\r\n",
        "   model.add(Bidirectional(LSTM(40)))\r\n",
        "   model.add(Dropout(0.1))\r\n",
        "   model.add(Dense(128, activation='relu'))\r\n",
        "   model.add(Dropout(0.1))\r\n",
        "   model.add(Dense(5, activation='softmax'))\r\n",
        "   model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy','mae'])\r\n",
        "   history = model.fit(X_train, y_train, epochs = 15, batch_size=64, verbose=1,shuffle=False)\r\n",
        "   scores = model.evaluate(X_test, y_test, verbose=1)\r\n",
        "   print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\r\n",
        "   cvscores.append(scores[1] * 100)\r\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "7818/7818 [==============================] - 45s 6ms/step - loss: 0.0113 - accuracy: 0.9968 - mae: 0.0025\n",
            "Epoch 2/15\n",
            "7818/7818 [==============================] - 48s 6ms/step - loss: 7.6685e-04 - accuracy: 0.9998 - mae: 1.1908e-04\n",
            "Epoch 3/15\n",
            "7818/7818 [==============================] - 45s 6ms/step - loss: 6.6131e-04 - accuracy: 0.9998 - mae: 1.0341e-04\n",
            "Epoch 4/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 5.5876e-04 - accuracy: 0.9999 - mae: 7.2895e-05\n",
            "Epoch 5/15\n",
            "7818/7818 [==============================] - 45s 6ms/step - loss: 2.8796e-04 - accuracy: 0.9999 - mae: 4.3810e-05\n",
            "Epoch 6/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 5.1233e-04 - accuracy: 0.9999 - mae: 5.9264e-05\n",
            "Epoch 7/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 3.1455e-04 - accuracy: 0.9999 - mae: 3.9139e-05\n",
            "Epoch 8/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 2.8333e-04 - accuracy: 0.9999 - mae: 3.7124e-05\n",
            "Epoch 9/15\n",
            "7818/7818 [==============================] - 45s 6ms/step - loss: 2.9995e-04 - accuracy: 0.9999 - mae: 3.7374e-05\n",
            "Epoch 10/15\n",
            "7818/7818 [==============================] - 45s 6ms/step - loss: 1.9444e-04 - accuracy: 1.0000 - mae: 2.5743e-05\n",
            "Epoch 11/15\n",
            "7818/7818 [==============================] - 45s 6ms/step - loss: 3.3096e-04 - accuracy: 0.9999 - mae: 3.0263e-05\n",
            "Epoch 12/15\n",
            "7818/7818 [==============================] - 45s 6ms/step - loss: 1.8019e-04 - accuracy: 1.0000 - mae: 2.2969e-05\n",
            "Epoch 13/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 2.5580e-04 - accuracy: 1.0000 - mae: 2.5213e-05\n",
            "Epoch 14/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 1.7390e-04 - accuracy: 1.0000 - mae: 2.4688e-05\n",
            "Epoch 15/15\n",
            "7818/7818 [==============================] - 49s 6ms/step - loss: 3.0720e-04 - accuracy: 0.9999 - mae: 2.6576e-05\n",
            "3909/3909 [==============================] - 6s 2ms/step - loss: 3.6257e-04 - accuracy: 0.9999 - mae: 3.6678e-05\n",
            "accuracy: 99.99%\n",
            "Epoch 1/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 0.0113 - accuracy: 0.9969 - mae: 0.0024\n",
            "Epoch 2/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 7.4075e-04 - accuracy: 0.9998 - mae: 1.1771e-04\n",
            "Epoch 3/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 6.5766e-04 - accuracy: 0.9998 - mae: 9.8100e-05\n",
            "Epoch 4/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 4.8491e-04 - accuracy: 0.9999 - mae: 7.2650e-05\n",
            "Epoch 5/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 3.6616e-04 - accuracy: 0.9999 - mae: 6.4834e-05\n",
            "Epoch 6/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 3.6601e-04 - accuracy: 0.9999 - mae: 4.3703e-05\n",
            "Epoch 7/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 4.7520e-04 - accuracy: 0.9999 - mae: 5.2568e-05\n",
            "Epoch 8/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 3.4020e-04 - accuracy: 0.9999 - mae: 4.1545e-05\n",
            "Epoch 9/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 3.6694e-04 - accuracy: 0.9999 - mae: 3.9358e-05\n",
            "Epoch 10/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 2.2795e-04 - accuracy: 0.9999 - mae: 3.0474e-05\n",
            "Epoch 11/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 2.3702e-04 - accuracy: 0.9999 - mae: 3.1816e-05\n",
            "Epoch 12/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 1.7483e-04 - accuracy: 1.0000 - mae: 2.4435e-05\n",
            "Epoch 13/15\n",
            "7818/7818 [==============================] - 48s 6ms/step - loss: 2.3565e-04 - accuracy: 1.0000 - mae: 2.3540e-05\n",
            "Epoch 14/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 2.7262e-04 - accuracy: 1.0000 - mae: 2.7031e-05\n",
            "Epoch 15/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 1.7065e-04 - accuracy: 1.0000 - mae: 1.7903e-05\n",
            "3909/3909 [==============================] - 6s 2ms/step - loss: 4.3259e-04 - accuracy: 0.9999 - mae: 2.9984e-05\n",
            "accuracy: 99.99%\n",
            "Epoch 1/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 0.0113 - accuracy: 0.9969 - mae: 0.0025\n",
            "Epoch 2/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 8.1922e-04 - accuracy: 0.9998 - mae: 1.3124e-04\n",
            "Epoch 3/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 5.5293e-04 - accuracy: 0.9999 - mae: 8.4658e-05\n",
            "Epoch 4/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 6.0442e-04 - accuracy: 0.9999 - mae: 7.7195e-05\n",
            "Epoch 5/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 3.7090e-04 - accuracy: 0.9999 - mae: 5.4133e-05\n",
            "Epoch 6/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 3.6441e-04 - accuracy: 0.9999 - mae: 4.7942e-05\n",
            "Epoch 7/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 3.5470e-04 - accuracy: 0.9999 - mae: 4.7587e-05\n",
            "Epoch 8/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 3.4407e-04 - accuracy: 0.9999 - mae: 4.7835e-05\n",
            "Epoch 9/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 3.5506e-04 - accuracy: 0.9999 - mae: 3.9422e-05\n",
            "Epoch 10/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 2.4153e-04 - accuracy: 1.0000 - mae: 2.7516e-05\n",
            "Epoch 11/15\n",
            "7818/7818 [==============================] - 49s 6ms/step - loss: 2.7494e-04 - accuracy: 0.9999 - mae: 3.3460e-05\n",
            "Epoch 12/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 1.2559e-04 - accuracy: 1.0000 - mae: 1.8370e-05\n",
            "Epoch 13/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 3.0314e-04 - accuracy: 0.9999 - mae: 3.3306e-05\n",
            "Epoch 14/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 2.4845e-04 - accuracy: 1.0000 - mae: 2.2327e-05\n",
            "Epoch 15/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 2.5906e-04 - accuracy: 1.0000 - mae: 2.3731e-05\n",
            "3909/3909 [==============================] - 6s 2ms/step - loss: 3.7936e-04 - accuracy: 0.9999 - mae: 3.7934e-05\n",
            "accuracy: 99.99%\n",
            "Epoch 1/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 0.0114 - accuracy: 0.9969 - mae: 0.0025\n",
            "Epoch 2/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 7.3829e-04 - accuracy: 0.9998 - mae: 1.1409e-04\n",
            "Epoch 3/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 5.7038e-04 - accuracy: 0.9998 - mae: 8.4021e-05\n",
            "Epoch 4/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 5.5798e-04 - accuracy: 0.9999 - mae: 7.0059e-05\n",
            "Epoch 5/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 4.2335e-04 - accuracy: 0.9999 - mae: 6.1376e-05\n",
            "Epoch 6/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 4.5870e-04 - accuracy: 0.9999 - mae: 5.9126e-05\n",
            "Epoch 7/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 4.1730e-04 - accuracy: 0.9999 - mae: 5.1389e-05\n",
            "Epoch 8/15\n",
            "7818/7818 [==============================] - 49s 6ms/step - loss: 3.3378e-04 - accuracy: 0.9999 - mae: 3.1263e-05\n",
            "Epoch 9/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 1.8694e-04 - accuracy: 0.9999 - mae: 3.0842e-05\n",
            "Epoch 10/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 4.1214e-04 - accuracy: 0.9999 - mae: 3.8373e-05\n",
            "Epoch 11/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 2.0993e-04 - accuracy: 1.0000 - mae: 2.6031e-05\n",
            "Epoch 12/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 3.5398e-04 - accuracy: 0.9999 - mae: 3.7142e-05\n",
            "Epoch 13/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 2.1128e-04 - accuracy: 1.0000 - mae: 2.2801e-05\n",
            "Epoch 14/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 2.4618e-04 - accuracy: 1.0000 - mae: 2.5867e-05\n",
            "Epoch 15/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 1.8174e-04 - accuracy: 1.0000 - mae: 1.6927e-05\n",
            "3909/3909 [==============================] - 6s 2ms/step - loss: 5.9721e-04 - accuracy: 0.9999 - mae: 5.3897e-05\n",
            "accuracy: 99.99%\n",
            "Epoch 1/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 0.0111 - accuracy: 0.9971 - mae: 0.0024\n",
            "Epoch 2/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 8.4075e-04 - accuracy: 0.9998 - mae: 1.2898e-04\n",
            "Epoch 3/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 7.6617e-04 - accuracy: 0.9998 - mae: 9.5823e-05\n",
            "Epoch 4/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 4.3411e-04 - accuracy: 0.9999 - mae: 6.8098e-05\n",
            "Epoch 5/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 4.1170e-04 - accuracy: 0.9999 - mae: 5.7502e-05\n",
            "Epoch 6/15\n",
            "7818/7818 [==============================] - 49s 6ms/step - loss: 4.4044e-04 - accuracy: 0.9999 - mae: 5.6735e-05\n",
            "Epoch 7/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 4.2451e-04 - accuracy: 0.9999 - mae: 4.3041e-05\n",
            "Epoch 8/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 3.6461e-04 - accuracy: 0.9999 - mae: 4.5222e-05\n",
            "Epoch 9/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 3.0103e-04 - accuracy: 0.9999 - mae: 3.2976e-05\n",
            "Epoch 10/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 2.1642e-04 - accuracy: 0.9999 - mae: 3.4552e-05\n",
            "Epoch 11/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 3.3457e-04 - accuracy: 0.9999 - mae: 3.3872e-05\n",
            "Epoch 12/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 2.3207e-04 - accuracy: 1.0000 - mae: 2.3973e-05\n",
            "Epoch 13/15\n",
            "7818/7818 [==============================] - 47s 6ms/step - loss: 3.6118e-04 - accuracy: 1.0000 - mae: 2.3904e-05\n",
            "Epoch 14/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 2.5875e-04 - accuracy: 1.0000 - mae: 2.6500e-05\n",
            "Epoch 15/15\n",
            "7818/7818 [==============================] - 46s 6ms/step - loss: 1.6115e-04 - accuracy: 1.0000 - mae: 1.8582e-05\n",
            "3909/3909 [==============================] - 6s 2ms/step - loss: 5.0309e-04 - accuracy: 0.9999 - mae: 4.1117e-05\n",
            "accuracy: 99.99%\n",
            "99.99% (+/- 0.00%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgiiAioi_4_M"
      },
      "source": [
        "target_names = ['Mirai', 'Scan', 'DoS', 'Normal', 'MITM ARP Spoofing']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epu1cGk0CPyM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39769b32-28fe-46d2-aa44-492084666c5d"
      },
      "source": [
        "#MODEL EVALUATION\n",
        "\n",
        "# print test_scores of accuracy,precision,recall,f1-score\n",
        "y_pred_test = model.predict(X_test)\n",
        "print(\"Test_Accuracy:\",metrics.accuracy_score(y_test, np.round(y_pred_test)))\n",
        "print(\"Test_Precision:\",metrics.precision_score(y_test, np.round(y_pred_test), average='weighted'))\n",
        "print(\"Test_Recall:\",metrics.recall_score(y_test, np.round(y_pred_test), average='weighted'))\n",
        "print(\"Test_f1-score:\",metrics.f1_score(y_test, np.round(y_pred_test), average='weighted'))\n",
        "print(classification_report(y_test, np.round(y_pred_test), target_names=target_names))\n",
        "\n",
        "# print train_scores of accuracy,precision,recall,f1-score\n",
        "y_pred_train = model.predict(X_train)\n",
        "print(\"Train_Accuracy:\",metrics.accuracy_score(y_train, np.round(y_pred_train)))\n",
        "print(\"Train_Precision:\",metrics.precision_score(y_train, np.round(y_pred_train), average='weighted'))\n",
        "print(\"Train_Recall:\",metrics.recall_score(y_train, np.round(y_pred_train), average='weighted'))\n",
        "print(\"Train_f1-score:\",metrics.f1_score(y_train, np.round(y_pred_train), average='weighted'))\n",
        "print(classification_report(y_train, np.round(y_pred_train), target_names=target_names))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test_Accuracy: 0.999904063701702\n",
            "Test_Precision: 0.9999040734421465\n",
            "Test_Recall: 0.999904063701702\n",
            "Test_f1-score: 0.9999040644201805\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "            Mirai       1.00      1.00      1.00     11815\n",
            "             Scan       1.00      1.00      1.00      7109\n",
            "              DoS       1.00      1.00      1.00     83057\n",
            "           Normal       1.00      1.00      1.00      8060\n",
            "MITM ARP Spoofing       1.00      1.00      1.00     15042\n",
            "\n",
            "        micro avg       1.00      1.00      1.00    125083\n",
            "        macro avg       1.00      1.00      1.00    125083\n",
            "     weighted avg       1.00      1.00      1.00    125083\n",
            "      samples avg       1.00      1.00      1.00    125083\n",
            "\n",
            "Train_Accuracy: 0.9999600265423758\n",
            "Train_Precision: 0.9999600290425497\n",
            "Train_Recall: 0.9999600265423758\n",
            "Train_f1-score: 0.9999600272805512\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "            Mirai       1.00      1.00      1.00     47576\n",
            "             Scan       1.00      1.00      1.00     28268\n",
            "              DoS       1.00      1.00      1.00    332252\n",
            "           Normal       1.00      1.00      1.00     32013\n",
            "MITM ARP Spoofing       1.00      1.00      1.00     60223\n",
            "\n",
            "        micro avg       1.00      1.00      1.00    500332\n",
            "        macro avg       1.00      1.00      1.00    500332\n",
            "     weighted avg       1.00      1.00      1.00    500332\n",
            "      samples avg       1.00      1.00      1.00    500332\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}