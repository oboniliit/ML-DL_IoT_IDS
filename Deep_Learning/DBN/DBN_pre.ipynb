{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"colab":{"name":"DBN_pre.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"scrolled":true,"id":"A6u-q8tEira3","outputId":"841db1b6-2de9-4578-f608-525667acae58"},"source":["import numpy as np\n","import tensorflow as tf\n","import pandas as pd\n","\n","np.random.seed(1337)  # for reproducibility\n","from sklearn.datasets import load_digits\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics.classification import accuracy_score\n","tf.compat.v1.Session()\n","from dbn import SupervisedDBNClassification\n","from sklearn import preprocessing\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n","  warnings.warn(message, FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"33AoH20TlZae","colab":{"base_uri":"https://localhost:8080/"},"outputId":"923bf7ac-7940-43c6-947f-5de9ea551506"},"source":["\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MzsR1fG_ira9"},"source":["# Normalize the data attributes \n","columns_to_named = [\"frameNumber\", \"frameTime\", \"frameLen\", \"ethSrc\", \"ethDst\",\n","       \"ipSrc\", \"ipDst\", \"ipProto\", \"ipLen\", \"tcpLen\", \"tcpSrcport\",\n","       \"tcpDstport\", \"Value\", \"normality\"]\n","    \n","    # Read the Dataset and Rename the Column\n","df = pd.read_csv(\"/content/drive/MyDrive/Code/dataset/Preprocessed_data.csv\",header=0,names=columns_to_named)\n","\n","col_norm = ['frameNumber', 'frameTime', 'frameLen', 'ethSrc', 'ethDst',\n","       'ipSrc', 'ipDst', 'ipProto', 'ipLen', 'tcpLen', 'tcpSrcport',\n","       'tcpDstport', 'Value']\n","X = df[col_norm]\n","y = df[\"normality\"]\n","# normalize the data attributes\n","X = preprocessing.normalize(X)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SHlDuLy2irbB","outputId":"2409a227-8930-4ec0-a5b6-3e17f97a1893"},"source":["# Training\n","classifier = SupervisedDBNClassification(hidden_layers_structure=[256, 256],\n","                                         learning_rate_rbm=0.05,\n","                                         learning_rate=0.1,\n","                                         n_epochs_rbm=10,\n","                                         n_iter_backprop=100,\n","                                         batch_size=32,\n","                                         activation_function='relu',\n","                                         dropout_p=0.2)\n","classifier.fit(X_train, y_train)\n","\n","# Save the model\n","classifier.save('model.pkl')\n","\n","# Restore it\n","classifier = SupervisedDBNClassification.load('model.pkl')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[START] Pre-training step:\n",">> Epoch 1 finished \tRBM Reconstruction error 0.009464\n",">> Epoch 2 finished \tRBM Reconstruction error 0.008201\n",">> Epoch 3 finished \tRBM Reconstruction error 0.007786\n",">> Epoch 4 finished \tRBM Reconstruction error 0.007751\n",">> Epoch 5 finished \tRBM Reconstruction error 0.007453\n",">> Epoch 6 finished \tRBM Reconstruction error 0.006824\n",">> Epoch 7 finished \tRBM Reconstruction error 0.007104\n",">> Epoch 8 finished \tRBM Reconstruction error 0.006760\n",">> Epoch 9 finished \tRBM Reconstruction error 0.006126\n",">> Epoch 10 finished \tRBM Reconstruction error 0.006159\n",">> Epoch 1 finished \tRBM Reconstruction error 0.003432\n",">> Epoch 2 finished \tRBM Reconstruction error 0.002877\n",">> Epoch 3 finished \tRBM Reconstruction error 0.002893\n",">> Epoch 4 finished \tRBM Reconstruction error 0.002962\n",">> Epoch 5 finished \tRBM Reconstruction error 0.002825\n",">> Epoch 6 finished \tRBM Reconstruction error 0.002828\n",">> Epoch 7 finished \tRBM Reconstruction error 0.002856\n",">> Epoch 8 finished \tRBM Reconstruction error 0.002805\n",">> Epoch 9 finished \tRBM Reconstruction error 0.002778\n",">> Epoch 10 finished \tRBM Reconstruction error 0.002799\n","[END] Pre-training step\n","[START] Fine tuning step:\n",">> Epoch 1 finished \tANN training loss 3.423529\n",">> Epoch 2 finished \tANN training loss 2.125000\n",">> Epoch 3 finished \tANN training loss 1.852921\n",">> Epoch 4 finished \tANN training loss 1.768367\n",">> Epoch 5 finished \tANN training loss 1.710828\n",">> Epoch 6 finished \tANN training loss 1.660525\n",">> Epoch 7 finished \tANN training loss 1.640641\n",">> Epoch 8 finished \tANN training loss 1.621367\n",">> Epoch 9 finished \tANN training loss 1.597472\n",">> Epoch 10 finished \tANN training loss 1.594189\n",">> Epoch 11 finished \tANN training loss 1.585223\n",">> Epoch 12 finished \tANN training loss 1.556048\n",">> Epoch 13 finished \tANN training loss 1.547917\n",">> Epoch 14 finished \tANN training loss 1.536288\n",">> Epoch 15 finished \tANN training loss 1.512967\n",">> Epoch 16 finished \tANN training loss 1.498702\n",">> Epoch 17 finished \tANN training loss 1.489782\n",">> Epoch 18 finished \tANN training loss 1.478525\n",">> Epoch 19 finished \tANN training loss 1.477306\n",">> Epoch 20 finished \tANN training loss 1.461904\n",">> Epoch 21 finished \tANN training loss 1.460181\n",">> Epoch 22 finished \tANN training loss 1.464078\n",">> Epoch 23 finished \tANN training loss 1.450947\n",">> Epoch 24 finished \tANN training loss 1.447566\n",">> Epoch 25 finished \tANN training loss 1.443736\n",">> Epoch 26 finished \tANN training loss 1.448737\n",">> Epoch 27 finished \tANN training loss 1.441102\n",">> Epoch 28 finished \tANN training loss 1.442459\n",">> Epoch 29 finished \tANN training loss 1.436099\n",">> Epoch 30 finished \tANN training loss 1.434983\n",">> Epoch 31 finished \tANN training loss 1.430324\n",">> Epoch 32 finished \tANN training loss 1.432025\n",">> Epoch 33 finished \tANN training loss 1.429883\n",">> Epoch 34 finished \tANN training loss 1.425547\n",">> Epoch 35 finished \tANN training loss 1.423120\n",">> Epoch 36 finished \tANN training loss 1.423018\n",">> Epoch 37 finished \tANN training loss 1.427936\n",">> Epoch 38 finished \tANN training loss 1.417751\n",">> Epoch 39 finished \tANN training loss 1.424676\n",">> Epoch 40 finished \tANN training loss 1.419150\n",">> Epoch 41 finished \tANN training loss 1.419603\n",">> Epoch 42 finished \tANN training loss 1.417992\n",">> Epoch 43 finished \tANN training loss 1.420528\n",">> Epoch 44 finished \tANN training loss 1.424318\n",">> Epoch 45 finished \tANN training loss 1.413788\n",">> Epoch 46 finished \tANN training loss 1.416727\n",">> Epoch 47 finished \tANN training loss 1.418183\n",">> Epoch 48 finished \tANN training loss 1.417218\n",">> Epoch 49 finished \tANN training loss 1.412479\n",">> Epoch 50 finished \tANN training loss 1.411660\n",">> Epoch 51 finished \tANN training loss 1.411443\n",">> Epoch 52 finished \tANN training loss 1.412308\n",">> Epoch 53 finished \tANN training loss 1.409085\n",">> Epoch 54 finished \tANN training loss 1.413678\n",">> Epoch 55 finished \tANN training loss 1.404914\n",">> Epoch 56 finished \tANN training loss 1.413254\n",">> Epoch 57 finished \tANN training loss 1.409756\n",">> Epoch 58 finished \tANN training loss 1.406071\n",">> Epoch 59 finished \tANN training loss 1.410330\n",">> Epoch 60 finished \tANN training loss 1.406820\n",">> Epoch 61 finished \tANN training loss 1.396229\n",">> Epoch 62 finished \tANN training loss 1.417301\n",">> Epoch 63 finished \tANN training loss 1.403690\n",">> Epoch 64 finished \tANN training loss 1.394543\n",">> Epoch 65 finished \tANN training loss 1.398907\n",">> Epoch 66 finished \tANN training loss 1.404719\n",">> Epoch 67 finished \tANN training loss 1.397340\n",">> Epoch 68 finished \tANN training loss 1.398311\n",">> Epoch 69 finished \tANN training loss 1.406804\n",">> Epoch 70 finished \tANN training loss 1.401999\n",">> Epoch 71 finished \tANN training loss 1.404827\n",">> Epoch 72 finished \tANN training loss 1.402731\n",">> Epoch 73 finished \tANN training loss 1.392808\n",">> Epoch 74 finished \tANN training loss 1.397432\n",">> Epoch 75 finished \tANN training loss 1.401924\n",">> Epoch 76 finished \tANN training loss 1.397337\n",">> Epoch 77 finished \tANN training loss 1.403898\n",">> Epoch 78 finished \tANN training loss 1.400820\n",">> Epoch 79 finished \tANN training loss 1.401232\n",">> Epoch 80 finished \tANN training loss 1.407984\n",">> Epoch 81 finished \tANN training loss 1.395788\n",">> Epoch 82 finished \tANN training loss 1.396289\n",">> Epoch 83 finished \tANN training loss 1.398553\n",">> Epoch 84 finished \tANN training loss 1.391292\n",">> Epoch 85 finished \tANN training loss 1.390943\n",">> Epoch 86 finished \tANN training loss 1.394880\n",">> Epoch 87 finished \tANN training loss 1.399330\n",">> Epoch 88 finished \tANN training loss 1.395528\n",">> Epoch 89 finished \tANN training loss 1.397647\n",">> Epoch 90 finished \tANN training loss 1.396932\n",">> Epoch 91 finished \tANN training loss 1.391185\n",">> Epoch 92 finished \tANN training loss 1.387857\n",">> Epoch 93 finished \tANN training loss 1.390464\n",">> Epoch 94 finished \tANN training loss 1.391536\n",">> Epoch 95 finished \tANN training loss 1.388316\n",">> Epoch 96 finished \tANN training loss 1.398022\n",">> Epoch 97 finished \tANN training loss 1.396042\n",">> Epoch 98 finished \tANN training loss 1.388061\n",">> Epoch 99 finished \tANN training loss 1.392073\n",">> Epoch 100 finished \tANN training loss 1.395153\n","[END] Fine tuning step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Cqs0wElRirbE","outputId":"712c1881-1c77-4bb6-bd38-440f739da684"},"source":["# Test accuracy\n","expected_test = y_test\n","predicted_test = classifier.predict(X_test)\n","print('Done.\\nAccuracy: %f' % accuracy_score(expected_test, np.round(predicted_test))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Done.\n","Accuracy: 0.921611\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uCWQ7priirbI"},"source":["#test accuracy\r\n","expected_test = y_test\r\n","predicted_test = classifier.predict(X_test)\r\n","print(\"Test_Accuracy:\",metrics.accuracy_score(expected_test, np.round(predicted_test)))\r\n","print(\"Test_Precision:\",metrics.precision_score(expected_test, np.round(predicted_test), average='weighted'))\r\n","print(\"Test_Recall:\",metrics.recall_score(expected_test, np.round(predicted_test), average='weighted'))\r\n","print(\"Test_f1-score:\",metrics.f1_score(expected_test, np.round(predicted_test), average='weighted'))\r\n","data = classification_report(expected_test,np.round(predicted_test),target_names=target_names)\r\n","print(data)\r\n","\r\n","#train accuracy\r\n","expected_train = y_train\r\n","predicted_train = classifier.predict(X_train)\r\n","print(\"Train_Accuracy:\",metrics.accuracy_score(expected_train, np.round(predicted_train)))\r\n","print(\"Train_Precision:\",metrics.precision_score(expected_train, np.round(predicted_train), average='weighted'))\r\n","print(\"Train_Recall:\",metrics.recall_score(expected_train, np.round(predicted_train), average='weighted'))\r\n","print(\"Train_f1-score:\",metrics.f1_score(expected_train, np.round(predicted_train), average='weighted'))\r\n","data = classification_report(expected_train,np.round(predicted_train),target_names=target_names)\r\n","print(data)"],"execution_count":null,"outputs":[]}]}