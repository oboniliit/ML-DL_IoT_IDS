{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "LSTM_NSL_KDD.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBEh4pZEF0Vn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "026a75ee-fa24-43e3-dd1e-be593560b5f6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUe0Zc1sFu7D"
      },
      "source": [
        "from __future__ import print_function\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import Normalizer\n",
        "import h5py\n",
        "from keras import callbacks\n",
        "from scipy.io import arff\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
        "import numpy as np\n",
        "np.random.seed(1337)  # for reproducibility\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from keras.layers import LSTM, SimpleRNN, GRU\n",
        "from keras.datasets import imdb\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import Normalizer\n",
        "import h5py\n",
        "from keras import callbacks\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
        "import h5py\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCuvvNKoFu7J"
      },
      "source": [
        " #load training dataset\n",
        "dataTrain = arff.loadarff('/content/drive/My Drive/KDDTrain20MultiClass.arff')\n",
        "dataset_train = pd.DataFrame(dataTrain[0])\n",
        "dataTest = arff.loadarff('/content/drive/My Drive/KDDTest21MultiClass.arff')\n",
        "dataset_test= pd.DataFrame(dataTrain[0])\n",
        "\n",
        "X_train = dataset_train.iloc[:, :-2].values\n",
        "Y_train = dataset_train.iloc[:, 41].values\n",
        "\n",
        "X_test = dataset_test.iloc[:, :-2].values\n",
        "Y_test = dataset_test.iloc[:, 41].values "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Hnt8lQuKS4Q"
      },
      "source": [
        "classes=[0,1,2,3,4,5]\n",
        "n_classes = 6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ndl8IL4S_nc"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "X_train.shape\n",
        "\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "x_train = np.array(X_train)\n",
        "x_test = np.array(X_test)\n",
        "y_train1 = np.array(Y_train)\n",
        "y_test1 = np.array(Y_test)\n",
        "\n",
        "y_train= to_categorical(y_train1)\n",
        "y_test= to_categorical(y_test1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dErGrfqy6hgY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f9b0eeb-b5e8-4035-acbe-c1c3c74f6f49"
      },
      "source": [
        "batch_size = 64\n",
        "# 1. define the network\n",
        "model = Sequential()\n",
        "model.add(LSTM(4, input_dim=40))  # try using a GRU instead, for fun\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy','mae'])\n",
        "history = model.fit(X_train, y_train, epochs = 10, batch_size=batch_size, verbose=1,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "394/394 [==============================] - 1s 2ms/step - loss: 1.2409 - accuracy: 0.6837 - mae: 0.2212\n",
            "Epoch 2/10\n",
            "394/394 [==============================] - 1s 2ms/step - loss: 0.7659 - accuracy: 0.7759 - mae: 0.1482\n",
            "Epoch 3/10\n",
            "394/394 [==============================] - 1s 2ms/step - loss: 0.6237 - accuracy: 0.7856 - mae: 0.1215\n",
            "Epoch 4/10\n",
            "394/394 [==============================] - 1s 2ms/step - loss: 0.5529 - accuracy: 0.7917 - mae: 0.1076\n",
            "Epoch 5/10\n",
            "394/394 [==============================] - 1s 2ms/step - loss: 0.5134 - accuracy: 0.7970 - mae: 0.0997\n",
            "Epoch 6/10\n",
            "394/394 [==============================] - 1s 2ms/step - loss: 0.4672 - accuracy: 0.8267 - mae: 0.0915\n",
            "Epoch 7/10\n",
            "394/394 [==============================] - 1s 2ms/step - loss: 0.4326 - accuracy: 0.8381 - mae: 0.0837\n",
            "Epoch 8/10\n",
            "394/394 [==============================] - 1s 2ms/step - loss: 0.4232 - accuracy: 0.8322 - mae: 0.0817\n",
            "Epoch 9/10\n",
            "394/394 [==============================] - 1s 2ms/step - loss: 0.4021 - accuracy: 0.8394 - mae: 0.0781\n",
            "Epoch 10/10\n",
            "394/394 [==============================] - 1s 2ms/step - loss: 0.3920 - accuracy: 0.8346 - mae: 0.0759\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IoT2MwhLgN8"
      },
      "source": [
        "target_names = ['DoS', 'U2R', 'R2L', 'Probe','Normal','Unknown']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-ljEuGvLGgG",
        "outputId": "97200962-f678-4fc4-bf39-be0e7ed1b98c"
      },
      "source": [
        "### train_accuracy\n",
        "import sklearn.metrics as metrics\n",
        "expected = y_train\n",
        "predicted = model.predict(X_train)\n",
        "data = classification_report(expected,np.round(predicted), target_names=target_names)\n",
        "print(data)\n",
        "\n",
        "print(\"Accuracy_Train:\",metrics.accuracy_score(expected, np.round(predicted)))\n",
        "print(\"Precision_Train:\",metrics.precision_score(expected, np.round(predicted), average='weighted'))\n",
        "print(\"Recall_Train:\",metrics.recall_score(expected, np.round(predicted), average='weighted'))\n",
        "print(\"f1-score_Train:\",metrics.f1_score(expected, np.round(predicted), average='weighted'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         DoS       0.00      0.00      0.00         0\n",
            "         U2R       0.99      0.97      0.98      9234\n",
            "         R2L       0.00      0.00      0.00        11\n",
            "       Probe       0.00      0.00      0.00       209\n",
            "      Normal       0.92      0.40      0.56      2289\n",
            "     Unknown       0.93      0.98      0.95     13449\n",
            "\n",
            "   micro avg       0.95      0.91      0.93     25192\n",
            "   macro avg       0.47      0.39      0.41     25192\n",
            "weighted avg       0.94      0.91      0.92     25192\n",
            " samples avg       0.91      0.91      0.91     25192\n",
            "\n",
            "Accuracy_Train: 0.9137821530644649\n",
            "Precision_Train: 0.9425293804616532\n",
            "Recall_Train: 0.9137821530644649\n",
            "f1-score_Train: 0.9182922364730853\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ytt4k9lfiwjw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "164e1bc9-e8af-4ad7-fc4b-95f836bea373"
      },
      "source": [
        "### test_accuracy\n",
        "expected = y_test\n",
        "predicted = model.predict(X_test)\n",
        "data = classification_report(expected, np.round(predicted), target_names=target_names)\n",
        "print(data)\n",
        "\n",
        "print(\"Accuracy:\",metrics.accuracy_score(expected, np.round(predicted)))\n",
        "print(\"Precision:\",metrics.precision_score(expected, np.round(predicted), average='weighted'))\n",
        "print(\"Recall:\",metrics.recall_score(expected, np.round(predicted), average='weighted'))\n",
        "print(\"f1-score:\",metrics.f1_score(expected, np.round(predicted), average='weighted'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         DoS       0.00      0.00      0.00         0\n",
            "         U2R       1.00      0.97      0.98      9234\n",
            "         R2L       0.00      0.00      0.00        11\n",
            "       Probe       0.00      0.00      0.00       209\n",
            "      Normal       0.97      0.35      0.51      2289\n",
            "     Unknown       0.94      0.97      0.95     13449\n",
            "\n",
            "   micro avg       0.96      0.91      0.93     25192\n",
            "   macro avg       0.48      0.38      0.41     25192\n",
            "weighted avg       0.95      0.91      0.92     25192\n",
            " samples avg       0.91      0.91      0.91     25192\n",
            "\n",
            "Accuracy: 0.9055652588123214\n",
            "Precision: 0.9519524399230924\n",
            "Recall: 0.9055652588123214\n",
            "f1-score: 0.9153295540411072\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}