{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "ML_NSL_KDD.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxntBcBWAt0h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89ae4d56-e3ca-43cd-c1e1-03cfba999167"
      },
      "source": [
        "!pip install scikit-plot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-plot in /usr/local/lib/python3.6/dist-packages (0.3.7)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.17.0)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy>=0.9->scikit-plot) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOCORD5-JQDX"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn import metrics as metrics\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import Normalizer, StandardScaler\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from scipy.io import arff\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "import scikitplot as skplt\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "from scipy import interp\n",
        "from itertools import cycle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Jsj39uaAt0z"
      },
      "source": [
        " #load training dataset\n",
        "dataTrain = arff.loadarff('/content/drive/MyDrive/Code/dataset/NSL-KDD/KDDTrain20MultiClass.arff')\n",
        "traindata = pd.DataFrame(dataTrain[0])\n",
        "dataTest = arff.loadarff('/content/drive/MyDrive/Code/dataset/NSL-KDD/KDDTest21MultiClass.arff')\n",
        "testdata = pd.DataFrame(dataTrain[0])\n",
        "\n",
        "X_train = traindata.iloc[:, :-1].values\n",
        "Y_train = traindata.iloc[:, 41].values\n",
        "\n",
        "X_test = testdata.iloc[:, :-1].values\n",
        "Y_test = testdata.iloc[:, 41].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaYl8WjE3uUR"
      },
      "source": [
        "sc = StandardScaler()\r\n",
        "X_train = sc.fit_transform(X_train)\r\n",
        "X_test = sc.transform(X_test)\r\n",
        "\r\n",
        "X_train.shape\r\n",
        "\r\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1]))\r\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1]))\r\n",
        "\r\n",
        "\r\n",
        "y_train = np.array(Y_train)\r\n",
        "y_test = np.array(Y_test)\r\n",
        "y_train= to_categorical(y_train)\r\n",
        "y_test= to_categorical(y_test)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQMVEgfI4w3o"
      },
      "source": [
        "target_names = ['DoS', 'U2R', 'R2L', 'Probe','Normal','Unknown']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhiTZ9zoIkay",
        "outputId": "0b69244c-f5ba-4b44-ebdd-73861a32c496"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzv6FG9iAt1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "624c7736-86e3-4f91-9ea8-bbe3ffedea84"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier \n",
        "model = OneVsRestClassifier(DecisionTreeClassifier(max_depth=3, random_state=0))\n",
        "model.fit(X_train, y_train)\n",
        "print(model)\n",
        "# make predictions\n",
        "expected_train = y_train\n",
        "predicted_train = model.predict(X_train)\n",
        "# summarize the fit of the model\n",
        "print(\"Train_Accuracy:\",metrics.accuracy_score(expected_train, np.round(predicted_train)))\n",
        "print(\"Train_Precision:\",metrics.precision_score(expected_train, np.round(predicted_train), average='weighted'))\n",
        "print(\"Train_Recall:\",metrics.recall_score(expected_train, np.round(predicted_train), average='weighted'))\n",
        "print(\"Train_f1-score:\",metrics.f1_score(expected_train, np.round(predicted_train), average='weighted'))\n",
        "data = classification_report(expected_train, np.round(predicted_train), target_names=target_names)\n",
        "print(data)\n",
        "\n",
        "expected_test = y_test\n",
        "predicted_test = model.predict(X_test)\n",
        "\n",
        "print(\"Test_Accuracy:\",metrics.accuracy_score(expected_test, np.round(predicted_test)))\n",
        "print(\"Test_Precision:\",metrics.precision_score(expected_test, np.round(predicted_test), average='weighted'))\n",
        "print(\"Test_Recall:\",metrics.recall_score(expected_test, np.round(predicted_test), average='weighted'))\n",
        "print(\"Test_f1-score:\",metrics.f1_score(expected_test, np.round(predicted_test), average='weighted'))\n",
        "data = classification_report(expected_test, np.round(predicted_test), target_names=target_names)\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 0 is present in all training examples.\n",
            "  str(classes[c]))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OneVsRestClassifier(estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
            "                                                     class_weight=None,\n",
            "                                                     criterion='gini',\n",
            "                                                     max_depth=3,\n",
            "                                                     max_features=None,\n",
            "                                                     max_leaf_nodes=None,\n",
            "                                                     min_impurity_decrease=0.0,\n",
            "                                                     min_impurity_split=None,\n",
            "                                                     min_samples_leaf=1,\n",
            "                                                     min_samples_split=2,\n",
            "                                                     min_weight_fraction_leaf=0.0,\n",
            "                                                     presort='deprecated',\n",
            "                                                     random_state=0,\n",
            "                                                     splitter='best'),\n",
            "                    n_jobs=None)\n",
            "Train_Accuracy: 0.9307716735471578\n",
            "Train_Precision: 0.9800512069749387\n",
            "Train_Recall: 0.9348205779612575\n",
            "Train_f1-score: 0.9552608471494024\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         DoS       0.00      0.00      0.00         0\n",
            "         U2R       1.00      0.94      0.97      9234\n",
            "         R2L       0.83      0.45      0.59        11\n",
            "       Probe       1.00      0.31      0.47       209\n",
            "      Normal       0.98      0.88      0.92      2289\n",
            "     Unknown       0.97      0.95      0.96     13449\n",
            "\n",
            "   micro avg       0.98      0.93      0.96     25192\n",
            "   macro avg       0.80      0.59      0.65     25192\n",
            "weighted avg       0.98      0.93      0.96     25192\n",
            " samples avg       0.93      0.93      0.93     25192\n",
            "\n",
            "Test_Accuracy: 0.9307716735471578\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test_Precision: 0.9800512069749387\n",
            "Test_Recall: 0.9348205779612575\n",
            "Test_f1-score: 0.9552608471494024\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         DoS       0.00      0.00      0.00         0\n",
            "         U2R       1.00      0.94      0.97      9234\n",
            "         R2L       0.83      0.45      0.59        11\n",
            "       Probe       1.00      0.31      0.47       209\n",
            "      Normal       0.98      0.88      0.92      2289\n",
            "     Unknown       0.97      0.95      0.96     13449\n",
            "\n",
            "   micro avg       0.98      0.93      0.96     25192\n",
            "   macro avg       0.80      0.59      0.65     25192\n",
            "weighted avg       0.98      0.93      0.96     25192\n",
            " samples avg       0.93      0.93      0.93     25192\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ls4nq7p4At1s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eb4e108-cbaf-4f3c-af9c-e40d1bb9b179"
      },
      "source": [
        "#random forest\r\n",
        "model = OneVsRestClassifier(RandomForestClassifier(max_depth=3, n_estimators=100))\r\n",
        "model.fit(X_train, y_train)\r\n",
        "print(model)\r\n",
        "# make predictions\r\n",
        "expected_train = y_train\r\n",
        "predicted_train = model.predict(X_train)\r\n",
        "# summarize the fit of the model\r\n",
        "print(\"Train_Accuracy:\",metrics.accuracy_score(expected_train, np.round(predicted_train)))\r\n",
        "print(\"Train_Precision:\",metrics.precision_score(expected_train, np.round(predicted_train), average='weighted'))\r\n",
        "print(\"Train_Recall:\",metrics.recall_score(expected_train, np.round(predicted_train), average='weighted'))\r\n",
        "print(\"Train_f1-score:\",metrics.f1_score(expected_train, np.round(predicted_train), average='weighted'))\r\n",
        "data = classification_report(expected_train, np.round(predicted_train), target_names=target_names)\r\n",
        "print(data)\r\n",
        "#conmat = confusion_matrix(expected,predicted)\r\n",
        "#print(conmat)\r\n",
        "expected_test = y_test\r\n",
        "predicted_test = model.predict(X_test)\r\n",
        "# summarize the fit of the model\r\n",
        "#data = classification_report(expected,np.round(predicted), target_names=target_names)\r\n",
        "#print(data)\r\n",
        "# conmat = confusion_matrix(expected,predicted)\r\n",
        "# print(conmat)\r\n",
        "\r\n",
        "print(\"Test_Accuracy:\",metrics.accuracy_score(expected_test, np.round(predicted_test)))\r\n",
        "print(\"Test_Precision:\",metrics.precision_score(expected_test, np.round(predicted_test), average='weighted'))\r\n",
        "print(\"Test_Recall:\",metrics.recall_score(expected_test, np.round(predicted_test), average='weighted'))\r\n",
        "print(\"Test_f1-score:\",metrics.f1_score(expected_test, np.round(predicted_test), average='weighted'))\r\n",
        "data = classification_report(expected_test, np.round(predicted_test), target_names=target_names)\r\n",
        "print(data)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 0 is present in all training examples.\n",
            "  str(classes[c]))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OneVsRestClassifier(estimator=RandomForestClassifier(bootstrap=True,\n",
            "                                                     ccp_alpha=0.0,\n",
            "                                                     class_weight=None,\n",
            "                                                     criterion='gini',\n",
            "                                                     max_depth=3,\n",
            "                                                     max_features='auto',\n",
            "                                                     max_leaf_nodes=None,\n",
            "                                                     max_samples=None,\n",
            "                                                     min_impurity_decrease=0.0,\n",
            "                                                     min_impurity_split=None,\n",
            "                                                     min_samples_leaf=1,\n",
            "                                                     min_samples_split=2,\n",
            "                                                     min_weight_fraction_leaf=0.0,\n",
            "                                                     n_estimators=100,\n",
            "                                                     n_jobs=None,\n",
            "                                                     oob_score=False,\n",
            "                                                     random_state=None,\n",
            "                                                     verbose=0,\n",
            "                                                     warm_start=False),\n",
            "                    n_jobs=None)\n",
            "Train_Accuracy: 0.9281517942203874\n",
            "Train_Precision: 0.9600877846039922\n",
            "Train_Recall: 0.9281914893617021\n",
            "Train_f1-score: 0.9413414931951614\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         DoS       0.00      0.00      0.00         0\n",
            "         U2R       1.00      0.90      0.94      9234\n",
            "         R2L       0.00      0.00      0.00        11\n",
            "       Probe       0.00      0.00      0.00       209\n",
            "      Normal       1.00      0.77      0.87      2289\n",
            "     Unknown       0.94      0.99      0.97     13449\n",
            "\n",
            "   micro avg       0.97      0.93      0.95     25192\n",
            "   macro avg       0.49      0.44      0.46     25192\n",
            "weighted avg       0.96      0.93      0.94     25192\n",
            " samples avg       0.93      0.93      0.93     25192\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test_Accuracy: 0.9281517942203874\n",
            "Test_Precision: 0.9600877846039922\n",
            "Test_Recall: 0.9281914893617021\n",
            "Test_f1-score: 0.9413414931951614\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         DoS       0.00      0.00      0.00         0\n",
            "         U2R       1.00      0.90      0.94      9234\n",
            "         R2L       0.00      0.00      0.00        11\n",
            "       Probe       0.00      0.00      0.00       209\n",
            "      Normal       1.00      0.77      0.87      2289\n",
            "     Unknown       0.94      0.99      0.97     13449\n",
            "\n",
            "   micro avg       0.97      0.93      0.95     25192\n",
            "   macro avg       0.49      0.44      0.46     25192\n",
            "weighted avg       0.96      0.93      0.94     25192\n",
            " samples avg       0.93      0.93      0.93     25192\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6Sf-K9eESJC",
        "outputId": "f1ed8d65-81a0-4392-cd11-a28e19ba5391"
      },
      "source": [
        "#SVM\r\n",
        "model = OneVsRestClassifier(SVC(C=1000))\r\n",
        "model.fit(X_train, y_train)\r\n",
        "print(model)\r\n",
        "# make predictions\r\n",
        "expected_train = y_train\r\n",
        "predicted_train = model.predict(X_train)\r\n",
        "# summarize the fit of the model\r\n",
        "print(\"Train_Accuracy:\",metrics.accuracy_score(expected_train, np.round(predicted_train)))\r\n",
        "print(\"Train_Precision:\",metrics.precision_score(expected_train, np.round(predicted_train), average='weighted'))\r\n",
        "print(\"Train_Recall:\",metrics.recall_score(expected_train, np.round(predicted_train), average='weighted'))\r\n",
        "print(\"Train_f1-score:\",metrics.f1_score(expected_train, np.round(predicted_train), average='weighted'))\r\n",
        "data = classification_report(expected_train, np.round(predicted_train), target_names=target_names)\r\n",
        "print(data)\r\n",
        "#conmat = confusion_matrix(expected,predicted)\r\n",
        "#print(conmat)\r\n",
        "expected_test = y_test\r\n",
        "predicted_test = model.predict(X_test)\r\n",
        "# summarize the fit of the model\r\n",
        "#data = classification_report(expected,np.round(predicted), target_names=target_names)\r\n",
        "#print(data)\r\n",
        "# conmat = confusion_matrix(expected,predicted)\r\n",
        "# print(conmat)\r\n",
        "\r\n",
        "print(\"Test_Accuracy:\",metrics.accuracy_score(expected_test, np.round(predicted_test)))\r\n",
        "print(\"Test_Precision:\",metrics.precision_score(expected_test, np.round(predicted_test), average='weighted'))\r\n",
        "print(\"Test_Recall:\",metrics.recall_score(expected_test, np.round(predicted_test), average='weighted'))\r\n",
        "print(\"Test_f1-score:\",metrics.f1_score(expected_test, np.round(predicted_test), average='weighted'))\r\n",
        "data = classification_report(expected_test, np.round(predicted_test), target_names=target_names)\r\n",
        "print(data)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 0 is present in all training examples.\n",
            "  str(classes[c]))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OneVsRestClassifier(estimator=SVC(C=1000, break_ties=False, cache_size=200,\n",
            "                                  class_weight=None, coef0=0.0,\n",
            "                                  decision_function_shape='ovr', degree=3,\n",
            "                                  gamma='scale', kernel='rbf', max_iter=-1,\n",
            "                                  probability=False, random_state=None,\n",
            "                                  shrinking=True, tol=0.001, verbose=False),\n",
            "                    n_jobs=None)\n",
            "Train_Accuracy: 0.9980946332168943\n",
            "Train_Precision: 0.9988842663418289\n",
            "Train_Recall: 0.9980946332168943\n",
            "Train_f1-score: 0.9984788060478675\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         DoS       0.00      0.00      0.00         0\n",
            "         U2R       1.00      1.00      1.00      9234\n",
            "         R2L       1.00      0.73      0.84        11\n",
            "       Probe       0.98      0.96      0.97       209\n",
            "      Normal       1.00      1.00      1.00      2289\n",
            "     Unknown       1.00      1.00      1.00     13449\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     25192\n",
            "   macro avg       0.83      0.78      0.80     25192\n",
            "weighted avg       1.00      1.00      1.00     25192\n",
            " samples avg       1.00      1.00      1.00     25192\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test_Accuracy: 0.9980946332168943\n",
            "Test_Precision: 0.9988842663418289\n",
            "Test_Recall: 0.9980946332168943\n",
            "Test_f1-score: 0.9984788060478675\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         DoS       0.00      0.00      0.00         0\n",
            "         U2R       1.00      1.00      1.00      9234\n",
            "         R2L       1.00      0.73      0.84        11\n",
            "       Probe       0.98      0.96      0.97       209\n",
            "      Normal       1.00      1.00      1.00      2289\n",
            "     Unknown       1.00      1.00      1.00     13449\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     25192\n",
            "   macro avg       0.83      0.78      0.80     25192\n",
            "weighted avg       1.00      1.00      1.00     25192\n",
            " samples avg       1.00      1.00      1.00     25192\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}